# RAG vs GraphRAG vs Text2Cypher Comparison

A comprehensive evaluation framework comparing three RAG approaches using the RAGAS evaluation framework.

## ğŸ¯ Project Overview

This project implements and benchmarks three RAG approaches:

1. **ChromaDB RAG**: Vector similarity search using embeddings
2. **GraphRAG**: Graph-Enchanced-Vector Search 
3. **Text2Cypher**: Natural language to Cypher query translation

All approaches are evaluated using RAGAS framework with automated visualizations.

For more information on approach types, see: 
https://neo4j.com/blog/developer/graphrag-field-guide-rag-patterns/

## ğŸ“ Project Structure

```
RAGvsGraphRAG/
â”œâ”€â”€ ğŸ“‚ benchmark/           # Benchmark scripts and data
â”‚   â”œâ”€â”€ ragas_benchmark.py  # Main RAGAS evaluation script
â”‚   â”œâ”€â”€ visualizations.py   # Automated chart generation
â”‚   â”œâ”€â”€ benchmark.csv       # Test questions and ground truth
â”‚   â””â”€â”€ BENCHMARK_README.md # Detailed benchmark documentation
â”œâ”€â”€ ğŸ“‚ tests/               # Test and validation scripts
â”‚   â”œâ”€â”€ test_ragas_setup.py # Quick 3-question validation
â”‚   â”œâ”€â”€ check_chromaDB.py   # ChromaDB health check
â”‚   â””â”€â”€ check_schema.py     # Neo4j schema inspection
â”œâ”€â”€ ğŸ“‚ PDFs/                # Source documents for processing
â”œâ”€â”€ ğŸ“‚ chroma_db/           # ChromaDB vector store data
â”œâ”€â”€ ğŸ“„ RAGvsGraphRAG.py     # Main RAG implementations
â”œâ”€â”€ ğŸ“„ pdf_processor.py     # PDF document processing
â”œâ”€â”€ ğŸ“„ graph_processor.py   # Neo4j graph construction
â””â”€â”€ ğŸ“„ requirements.txt     # Python dependencies
```

## ğŸš€ Quick Start

### 1. Environment Setup
```bash
# Install dependencies
pip install -r requirements.txt

# Set up environment variables
# Create .env file with:
# NEO4J_URI=your_neo4j_uri
# NEO4J_USERNAME=your_username  
# NEO4J_PASSWORD=your_password
# OPENAI_API_KEY=your_openai_key
```

### 2. Process Documents
```bash
# Process PDFs and populate both ChromaDB and Neo4j
python pdf_processor.py
python graph_processor.py
```

### 3. Validate Setup
```bash
# Quick health checks
python tests/check_chromaDB.py
python tests/check_schema.py

# Test with 3 sample questions
python tests/test_ragas_setup.py
```

### 4. Run Full Benchmark
```bash
# Complete evaluation with 20 questions
python benchmark/ragas_benchmark.py
```

## ğŸ” Key Components

### RAG Implementations (`RAGvsGraphRAG.py`)

#### ChromaDB RAG
- Vector similarity search using OpenAI embeddings
- Simple document chunk retrieval

#### GraphRAG
- [GraphRAG Field Guide](https://neo4j.com/blog/developer/graphrag-field-guide-rag-patterns/)
- Neo4j Graph-Enchanced Vector Search
- Enhanced context through entity traversal
- Safe graph traversal preventing chunk cross-contamination

#### Text2Cypher
- [Text2Cypher Blog Post](https://neo4j.com/blog/developer/effortless-rag-text2cypherretriever/)
- [Text2Cypher Implementation](https://github.com/neo4j/rag-evaluation/blob/main/scripts/run_experiment_from_config_file.py)

- Natural language to Cypher query translation
- Direct graph database querying
- Few-shot examples for query generation

### Benchmark Framework (`benchmark/`)
- Three-way RAGAS evaluation using GPT-4o-mini as evaluator
- Measures Context Recall, Faithfulness, and Factual Correctness
- Automated professional visualizations (bar charts, heatmaps, pie charts)
- Organized results in `benchmark_outputs/` folder


## ğŸ“ˆ Evaluation Metrics

### Context Recall (0.0-1.0)
**What it measures**: How well the retrieval system finds relevant information  
**Process**: LLM evaluates if retrieved contexts contain information needed to answer the question

### Faithfulness (0.0-1.0)  
**What it measures**: How faithful the generated answer is to retrieved context  
**Process**: Compares generated answer against retrieved documents for factual consistency

### Factual Correctness (0.0-1.0)
**What it measures**: How factually accurate the response is compared to ground truth  
**Process**: Compares generated answer against reference answer for accuracy

## ğŸ› ï¸ Development

### Adding New Documents
1. Place PDFs in `PDFs/` folder
2. Run `python pdf_processor.py`
3. Run `python graph_processor.py`

### Implementing into your own data & modifying Evaluation
- Edit `benchmark/benchmark.csv` to add/modify test questions
- Adjust metrics in `benchmark/ragas_benchmark.py`
- Update nodes, relationships and entity types in `graph_processor.py`
- Modify cypher_retriever in `RAGvsGraphRAG.py`

## ğŸ“š Documentation

- **Benchmark Details**: See `benchmark/BENCHMARK_README.md`
- **Schema Inspection**: Run `python tests/check_schema.py`