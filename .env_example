# Model Provider Configuration
#mine
#Johns
#Michaels

# Options: openai, ollama
LLM_PROVIDER=ollama
EMBEDDING_PROVIDER=ollama

# LLM Model Selection
# OpenAI options: gpt-4o-mini, gpt-4.1-mini, gpt-4o, gpt-4-turbo, gpt-3.5-turbo
# Ollama options: qwen3:8b, gemma3:7b, gemma3:12b, llama3:8b, mistral:7b
LLM_MODEL=qwen3:8b

# Fallback Model (used when LLM_MODEL is not recognized)
# Should be a model that's available in your setup
LLM_FALLBACK_MODEL=qwen3:8b

# Embedding Model Selection  
# OpenAI options: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
# Ollama options: nomic-embed-text, nomic-text-embed
EMBEDDING_MODEL=nomic-embed-text

# Model Parameters
MODEL_TEMPERATURE=0.0
MODEL_SEED=42
MAX_TOKENS=

# OpenAI Configuration
OPENAI_API_KEY=

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
# Request timeout in seconds (default: 600 = 10 minutes for RAGAS)
OLLAMA_REQUEST_TIMEOUT=600
# Keep alive time for Ollama models (default: 10m)
OLLAMA_KEEP_ALIVE=10m

# RAGAS Evaluation Configuration
# Maximum retries for timeout errors (default: 2)
RAGAS_MAX_RETRIES=2
# Timeout per metric in seconds (default: 120)
RAGAS_METRIC_TIMEOUT=120
# Overall evaluation timeout in seconds (default: 600 = 10 minutes)
RAGAS_OVERALL_TIMEOUT=600
# Force sequential processing to avoid parallel job timeouts
RAGAS_MAX_WORKERS=1
RAGAS_DISABLE_PARALLEL=true
# Evaluation context flag for extended timeouts
EVALUATION_CONTEXT=RAGAS

# Neo4j Configuration
NEO4J_URI=
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD= 