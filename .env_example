# Model Provider Configuration
# Options: openai, ollama, vertexai
LLM_PROVIDER=
EMBEDDING_PROVIDER=

# OpenAI API Key
OPENAI_API_KEY=

# LLM Model Selection
# OpenAI options: gpt-4o-mini, gpt-4.1-mini, gpt-4o, gpt-4-turbo, gpt-3.5-turbo
# Ollama options: qwen3:8b, gemma3:7b, gemma3:12b, llama3:8b, mistral:7b
# VertexAI options: gemini-2.5-pro, gemini-1.5-pro, gemini-1.5-flash
LLM_MODEL=

# Fallback Model (used when LLM_MODEL is not recognized)
# Should be a model that's available in your setup
LLM_FALLBACK_MODEL=

# Embedding Model Selection  
# OpenAI options: text-embedding-3-small (1536 dim), text-embedding-3-large (3072 dim), text-embedding-ada-002 (1536 dim)
# Ollama options: nomic-embed-text (768 dim), nomic-text-embed (768 dim)
# VertexAI options: text-embedding-005 (768 dim)
EMBEDDING_MODEL=

# Embedding Dimensions (Optional - auto-detected if not specified)
# Override this ONLY if you need to manually specify dimensions
# Common values: 768 (VertexAI, Ollama nomic), 1536 (OpenAI small/ada-002), 3072 (OpenAI large)
# Leave empty for automatic detection based on EMBEDDING_MODEL
EMBEDDING_DIMENSION=

# Model Parameters
MODEL_TEMPERATURE=0.0
MODEL_SEED=42
MAX_TOKENS=

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
# Request timeout in seconds (default: 600 = 10 minutes for RAGAS)
OLLAMA_REQUEST_TIMEOUT=600
# Keep alive time for Ollama models (default: 10m)
OLLAMA_KEEP_ALIVE=10m

# RAGAS Evaluation Configuration
# Maximum retries for timeout errors (default: 2)
RAGAS_MAX_RETRIES=2
# Timeout per metric in seconds (default: 120)
RAGAS_METRIC_TIMEOUT=120
# Overall evaluation timeout in seconds (default: 600 = 10 minutes)
RAGAS_OVERALL_TIMEOUT=600
# Force sequential processing to avoid parallel job timeouts
RAGAS_MAX_WORKERS=1
RAGAS_DISABLE_PARALLEL=true
# Evaluation context flag for extended timeouts
EVALUATION_CONTEXT=RAGAS

# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=
NEO4J_DATABASE=neo4j
CLIENT_NEO4J_DATABASE=neo4j